{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f24f250",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01efbbc1",
   "metadata": {},
   "source": [
    "Import lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9629fbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic\n",
    "import os\n",
    "import math\n",
    "\n",
    "#analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Statistik\n",
    "import scipy.stats as stats\n",
    "\n",
    "#plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c347d5f",
   "metadata": {},
   "source": [
    "# folder Force data (novel loadsol 2)\n",
    "Time[secs]: Zeit  \n",
    "Heel: Ferse   \n",
    "Midfoot: Fußgewölbe  \n",
    "Forefoot: Zehe  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "584f474a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time[secs]</th>\n",
       "      <th>PRY201_L_Heel</th>\n",
       "      <th>PRY201_L_Midfoot</th>\n",
       "      <th>PRY201_L_Forefoot</th>\n",
       "      <th>PRY201_L</th>\n",
       "      <th>Time[secs].1</th>\n",
       "      <th>PRY202_R_Forefoot</th>\n",
       "      <th>PRY202_R_Midfoot</th>\n",
       "      <th>PRY202_R_Heel</th>\n",
       "      <th>PRY202_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>99.71</td>\n",
       "      <td>124.49</td>\n",
       "      <td>147.5</td>\n",
       "      <td>371.7</td>\n",
       "      <td>0</td>\n",
       "      <td>119.68</td>\n",
       "      <td>99.84</td>\n",
       "      <td>157.44</td>\n",
       "      <td>376.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>102.07</td>\n",
       "      <td>124.49</td>\n",
       "      <td>147.5</td>\n",
       "      <td>374.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>122.24</td>\n",
       "      <td>99.84</td>\n",
       "      <td>160</td>\n",
       "      <td>382.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>99.71</td>\n",
       "      <td>122.13</td>\n",
       "      <td>144.55</td>\n",
       "      <td>366.39</td>\n",
       "      <td>0.02</td>\n",
       "      <td>119.68</td>\n",
       "      <td>99.84</td>\n",
       "      <td>160</td>\n",
       "      <td>379.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03</td>\n",
       "      <td>99.71</td>\n",
       "      <td>122.13</td>\n",
       "      <td>142.19</td>\n",
       "      <td>364.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>122.24</td>\n",
       "      <td>102.4</td>\n",
       "      <td>160</td>\n",
       "      <td>384.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04</td>\n",
       "      <td>97.35</td>\n",
       "      <td>122.13</td>\n",
       "      <td>142.19</td>\n",
       "      <td>361.67</td>\n",
       "      <td>0.04</td>\n",
       "      <td>124.8</td>\n",
       "      <td>102.4</td>\n",
       "      <td>160</td>\n",
       "      <td>387.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Time[secs] PRY201_L_Heel PRY201_L_Midfoot PRY201_L_Forefoot PRY201_L   \\\n",
       "0          0         99.71           124.49             147.5     371.7   \n",
       "1       0.01        102.07           124.49             147.5    374.06   \n",
       "2       0.02         99.71           122.13            144.55    366.39   \n",
       "3       0.03         99.71           122.13            142.19    364.03   \n",
       "4       0.04         97.35           122.13            142.19    361.67   \n",
       "\n",
       "  Time[secs].1 PRY202_R_Forefoot PRY202_R_Midfoot PRY202_R_Heel PRY202_R  \n",
       "0            0            119.68            99.84        157.44   376.96  \n",
       "1         0.01            122.24            99.84           160   382.08  \n",
       "2         0.02            119.68            99.84           160   379.52  \n",
       "3         0.03            122.24            102.4           160   384.64  \n",
       "4         0.04             124.8            102.4           160    387.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = r\"C:/Users/user/Desktop/Fatemeh/Analysis_Data/data/raw/Force data (novel loadsol 2)/Force data/loadsolASCII_25-11-11 09-24-19-079.txt\"\n",
    "\n",
    "df = pd.read_csv(\n",
    "    file_path,\n",
    "    sep=\"\\t\",        # جداکننده TAB\n",
    "    decimal=\",\",     # تبدیل کاما به نقطه اعشاری\n",
    ")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "016621b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " file: loadsolASCII_25_11_11_09_24_19_079_Gravel -- name dataframe: loadsolASCII_25-11-11 09-24-19-079_Gravel.txt\n",
      " file: loadsolASCII_25_11_11_09_38_11_074_Asphalt -- name dataframe: loadsolASCII_25-11-11 09-38-11-074_Asphalt.txt\n",
      " file: loadsolASCII_25_11_11_09_52_01_474_Sand -- name dataframe: loadsolASCII_25-11-11 09-52-01-474_Sand.txt\n",
      " file: loadsolASCII_25_11_11_10_06_34_305_Grass -- name dataframe: loadsolASCII_25-11-11 10-06-34-305_Grass.txt\n",
      " file: loadsolASCII_25_11_11_10_09_51_519_Grass -- name dataframe: loadsolASCII_25-11-11 10-09-51-519_Grass.txt\n",
      " file: loadsolASCII_25_11_11_13_49_21_080_Grass -- name dataframe: loadsolASCII_25-11-11 13-49-21-080_Grass.txt\n",
      " file: loadsolASCII_25_11_11_13_54_44_511_Grass -- name dataframe: loadsolASCII_25-11-11 13-54-44-511_Grass.txt\n",
      " file: loadsolASCII_25_11_11_14_09_23_595_Sand -- name dataframe: loadsolASCII_25-11-11 14-09-23-595_Sand.txt\n",
      " file: loadsolASCII_25_11_11_14_21_20_634_Asphalt -- name dataframe: loadsolASCII_25-11-11 14-21-20-634_Asphalt.txt\n",
      " file: loadsolASCII_25_11_11_14_28_52_974_Gravel -- name dataframe: loadsolASCII_25-11-11 14-28-52-974_Gravel.txt\n",
      " file: loadsolASCII_25_11_13_10_16_07_282_Asphalt -- name dataframe: loadsolASCII_25-11-13 10-16-07-282_Asphalt.txt\n",
      " file: loadsolASCII_25_11_13_10_29_20_864_Grass -- name dataframe: loadsolASCII_25-11-13 10-29-20-864_Grass.txt\n",
      " file: loadsolASCII_25_11_13_10_45_28_787_Sand -- name dataframe: loadsolASCII_25-11-13 10-45-28-787_Sand.txt\n",
      " file: loadsolASCII_25_11_13_11_00_05_455_Forest -- name dataframe: loadsolASCII_25-11-13 11-00-05-455_Forest.txt\n",
      " file: loadsolASCII_25_11_13_13_42_38_135_Wood -- name dataframe: loadsolASCII_25-11-13 13-42-38-135_Wood.txt\n",
      " file: loadsolASCII_25_11_13_13_53_39_763_Wood -- name dataframe: loadsolASCII_25-11-13 13-53-39-763_Wood.txt\n",
      " file: loadsolASCII_25_11_13_14_12_44_574_Grass -- name dataframe: loadsolASCII_25-11-13 14-12-44-574_Grass.txt\n",
      " file: loadsolASCII_25_11_13_14_29_01_831_Sand -- name dataframe: loadsolASCII_25-11-13 14-29-01-831_Sand.txt\n",
      " file: loadsolASCII_25_11_13_14_44_02_331_Asphalt -- name dataframe: loadsolASCII_25-11-13 14-44-02-331_Asphalt.txt\n",
      " file: loadsolASCII_25_11_14_09_25_59_897_Sand -- name dataframe: loadsolASCII_25-11-14 09-25-59-897_Sand.txt\n",
      " file: loadsolASCII_25_11_14_09_43_39_794_Grass -- name dataframe: loadsolASCII_25-11-14 09-43-39-794_Grass.txt\n",
      " file: loadsolASCII_25_11_14_10_00_15_439_Asphalt -- name dataframe: loadsolASCII_25-11-14 10-00-15-439_Asphalt.txt\n",
      " file: loadsolASCII_25_11_14_10_07_53_125_Wood -- name dataframe: loadsolASCII_25-11-14 10-07-53-125_Wood.txt\n",
      " file: loadsolASCII_25_11_16_13_47_50_266_Forest -- name dataframe: loadsolASCII_25-11-16 13-47-50-266_Forest.txt\n",
      " file: loadsolASCII_25_11_16_14_07_55_722_Asphalt -- name dataframe: loadsolASCII_25-11-16 14-07-55-722_Asphalt.txt\n",
      " file: loadsolASCII_25_11_16_14_29_02_178_Sand -- name dataframe: loadsolASCII_25-11-16 14-29-02-178_Sand.txt\n",
      " file: loadsolASCII_25_11_16_14_46_47_845_Grass -- name dataframe: loadsolASCII_25-11-16 14-46-47-845_Grass.txt\n",
      " file: loadsolASCII_25_11_17_09_15_09_073_Sand -- name dataframe: loadsolASCII_25-11-17 09-15-09-073_Sand.txt\n",
      " file: loadsolASCII_25_11_17_09_27_24_980_Grass -- name dataframe: loadsolASCII_25-11-17 09-27-24-980_Grass.txt\n",
      " file: loadsolASCII_25_11_17_09_44_13_137_Forest -- name dataframe: loadsolASCII_25-11-17 09-44-13-137_Forest.txt\n",
      " file: loadsolASCII_25_11_17_09_53_52_492_Forest -- name dataframe: loadsolASCII_25-11-17 09-53-52-492_Forest.txt\n",
      " file: loadsolASCII_25_11_17_10_09_36_341_Asphalt -- name dataframe: loadsolASCII_25-11-17 10-09-36-341_Asphalt.txt\n"
     ]
    }
   ],
   "source": [
    "#path\n",
    "path = r\"C:/Users/user/Desktop/Fatemeh/Analysis_Data/data/raw/Force data (novel loadsol 2)/All by category\"\n",
    "\n",
    "# read all data when that is .txt\n",
    "file_names = [f for f in os.listdir(path) if f.endswith('.txt')]\n",
    "\n",
    "#clear name and remove space and - from name\n",
    "def sanitize_name(name: str) -> str:\n",
    "    name = name.replace(\".txt\", \"\")\n",
    "    name = name.replace(\" \", \"_\").replace(\"-\", \"_\")\n",
    "    name = ''.join(c if c.isalnum() or c == '_' else '_' for c in name)\n",
    "    if name and name[0].isdigit():\n",
    "        name = '_' + name\n",
    "    return name\n",
    "\n",
    "# read all data\n",
    "for file_name in file_names:\n",
    "    var_name = sanitize_name(file_name)\n",
    "    file_path = os.path.join(path, file_name)\n",
    "    \n",
    "    print(f\" file: {var_name} -- name dataframe: {file_name}\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(\n",
    "            file_path,\n",
    "            sep=\"\\t\",\n",
    "            decimal=\",\",\n",
    "            engine=\"python\"\n",
    "        )\n",
    "        df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "        \n",
    "        # name of data frame\n",
    "        globals()[var_name] = df\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" --------Error---- {file_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a90d7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " file: loadsolASCII_25_11_11_09_24_19_079 -- name dataframe: loadsolASCII_25-11-11 09-24-19-079.txt\n",
      "Saved as CSV: C:/Users/user/Desktop/Fatemeh/Analysis_Data/data/raw/Force data (novel loadsol 2)/Force data csv\\loadsolASCII_25_11_11_09_24_19_079.csv\n",
      " file: loadsolASCII_25_11_11_09_38_11_074 -- name dataframe: loadsolASCII_25-11-11 09-38-11-074.txt\n",
      "Saved as CSV: C:/Users/user/Desktop/Fatemeh/Analysis_Data/data/raw/Force data (novel loadsol 2)/Force data csv\\loadsolASCII_25_11_11_09_38_11_074.csv\n"
     ]
    }
   ],
   "source": [
    "# read path\n",
    "input_path = r\"C:/Users/user/Desktop/Fatemeh/Analysis_Data/data/raw/Force data (novel loadsol 2)/Force data\"\n",
    "\n",
    "#save path\n",
    "output_path = r\"C:/Users/user/Desktop/Fatemeh/Analysis_Data/data/raw/Force data (novel loadsol 2)/Force data csv\"\n",
    "\n",
    "# read name of file with end by .txt\n",
    "file_names = [f for f in os.listdir(input_path) if f.endswith('.txt')]\n",
    "\n",
    "# Clear name of dataframe\n",
    "def sanitize_name(name: str) -> str:\n",
    "    name = name.replace(\".txt\", \"\")\n",
    "    name = name.replace(\" \", \"_\").replace(\"-\", \"_\")\n",
    "    name = ''.join(c if c.isalnum() or c == '_' else '_' for c in name)\n",
    "    if name and name[0].isdigit():\n",
    "        name = '_' + name\n",
    "    return name\n",
    "\n",
    "# read file.txt\n",
    "for file_name in file_names:\n",
    "    var_name = sanitize_name(file_name)\n",
    "    file_path = os.path.join(input_path, file_name)\n",
    "    \n",
    "    print(f\" file: {var_name} -- name dataframe: {file_name}\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(\n",
    "            file_path,\n",
    "            sep=\"\\t\",\n",
    "            decimal=\",\",\n",
    "            engine=\"python\"\n",
    "        )\n",
    "        \n",
    "        df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "        \n",
    "        globals()[var_name] = df\n",
    "        # save as .csv\n",
    "        csv_file_path = os.path.join(output_path, f\"{var_name}.csv\")\n",
    "        df.to_csv(csv_file_path, index=False) \n",
    "        \n",
    "        print(f\"Saved as CSV: {csv_file_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" --------Error---- {file_name}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
